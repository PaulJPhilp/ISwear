---
title: Shannon's Law
---

## Information Theory's Fundamental Law

Shannon's Law, developed by [Claude Shannon](https://en.wikipedia.org/wiki/Claude_Shannon) in 1948, establishes the maximum rate at which information can be transmitted over a communication channel.

### The Law

The Shannon-Hartley theorem states that channel capacity C (in bits per second) is:

C = B × log₂(1 + S/N)

Where:
- B is the bandwidth in hertz
- S/N is the signal-to-noise ratio
- log₂ represents the binary logarithm

### Impact

This fundamental law:
- Sets the theoretical limit for data compression
- Guides the design of communication systems
- Forms the basis for modern digital communications
- Enables efficient error correction in data transmission

Shannon's work revolutionized our understanding of information and laid the groundwork for the digital age.
